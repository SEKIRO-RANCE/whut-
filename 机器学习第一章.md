## 数据集的定义

数据集是数据的集合，数据集主要划分为训练集与测试集。

- **训练集**：用于训练模型，可以进一步划分为训练集与验证集。
  - 验证集：可选可不选，主要用于调整模型的超参数。
- **测试集**：用于评估模型的准确度，测试集不可以用于训练，否则会导致过拟合。

## 数据集的重要概念

数据集有三个重要概念：样本、对象和属性。

- **样本**：数据集中每个独立的实例。例如，在客流量预测中，样本可以是一整天的数据。
- **属性**：样本中包含的具体元素。例如，这一天的数据中包含天气、节假日等属性。
- **属性值**：属性的具体特征。例如，天气可以有天晴、阴天等属性，节假日可以有是否为节假日的属性值。

## 标记与标记空间

- **标记**：标记是我们提供给模型的标准答案。训练过程其实就是对比模型的预测结果与标记，然后不断调整模型的过程。
- **标记空间**：标记空间是最开始定义的标记区域，规定了模型能够输出的结果范围。

## 维度与输入空间

- **维度**：维度是指一个样本的属性数量。例如，如果一个样本有三个属性（如年龄、身高、体重），则该样本的维度为3。
- **输入空间**：输入空间是由样本的属性数量构成的坐标系空间。例如，对于一个三维样本，其输入空间是三维坐标系。

## 学习方法分类

机器学习按学习方法分类一般分为四类：监督学习、无监督学习、半监督学习、强化学习。其中最重要、应用最广的方法是监督学习。

- **监督学习**：
  - 特点：数据集中每个样本都有标记（即标准答案）。
  - 目标：通过学习输入与标记之间的映射关系，预测新样本的标记。
  - 示例：分类问题、回归问题。

### 分类问题（Classification）

- 定义：在监督学习中，当输出空间 $\mathcal{Y}$ 为离散取值（例如 {0,1}、{猫,狗,鸟}）时，称为分类问题。
- 学习过程：给定一组训练样本 $(x^{(i)}, y^{(i)})$（输入可以是离散或连续的特征），学习得到模型/函数 $f(x)$（或 $h_\theta(x)$），用于从输入预测类别。
- 预测/分类过程：面对新的输入 $x$，模型输出对应的离散类别 $\hat{y}$。
- 我们一般使用精确率，召回率，F1值来进行判断模型的优劣。
- 用于网络安全，图像处理，文本分类

### 标注问题 

- 标注问题是分类问题的推广，标注问题的精髓在于，当你输入一个维度时，得到一个维度的输出，当你输入n个维度时，得到n个维度的输出，即序列长度相等，主要集中于词性标注等场景。
- 标注问题注重于结构预测，即前后标签的联系，会通过你给出的维度之间的结构，来判断并输出
-即接收有序输入，关注输入结构，输出对齐维度
-用于信息抽取，自然语言处理，文本分类

### 回归问题

- 回归问题的输出是一个连续的函数，即通过输入寻找拟合曲线
- 通常用R方跟MAE,MAPE,RMSE来判断模型优劣
- 用于金融预测，旅游预测，股票预测等


### 剩余学习方法：

- **无监督学习**：
  - 特点：数据集中样本没有标记。
  - 目标：通过分析样本的内在结构，发现数据的模式或分组。
  - 示例：聚类问题、降维问题。

- **半监督学习**：
  - 特点：训练数据中只有一部分样本有标记，另一部分没有标记。
  - 目标：结合少量有标记数据与大量无标记数据进行学习，提升模型泛化能力。
  - 示例：用少量人工标注图片 + 大量未标注图片进行分类。

- **强化学习**：
  - 特点：智能体（Agent）在环境（Environment）中通过试错获得奖励（Reward）信号，通常没有直接的“标准答案”。
  - 目标：学习策略（Policy），使长期累计奖励最大化。
  - 示例：游戏对战、机器人控制。

## 机器学习的三大要素

机器学习的要素主要分为以下三种：

- **模型**：
  - 定义：模型是对问题的数学表示，用于描述输入与输出之间的关系。
  - 分类：
    - **生成模型**：
      - 定义：生成模型研究各个特征之间的潜在联系，反映数据之间的关系，体现潜在联系。
      - 特点：
        - 收敛速度更快。
        - 计算更复杂。
    - **判别模型**：
      - 定义：判别模型研究输入与输出的直接联系。
      - 特点：
        - 易于进行数据抽象与量化（例如将文字转为向量，减少数据细节等操作）。
        - 对数据细节的容忍度更大。
        - 简单易懂，可以简化学习问题。

- **策略**：
  - 定义：策略是衡量模型好坏的标准，通常通过损失函数或目标函数来定义。
  - 分类：
    - **损失函数**：
      - 定义：专注于单一样本的预测结果与真值之间的误差。
      - 作用：用来度量单个样本预测错误的程度。
    - **风险函数/代价函数**：
      - 定义：通常被认为是一类函数，是所有样本误差的平均，即损失函数的平均。
      - 作用：
        - 用来度量预测错误的程度，也就是模型的经验风险。
        - 度量模型对于多个样本的预测准确度。
    - **基本策略**：
      - **经验风险最小化（ERM）**：
        - 定义：主要关注模型的算法是否准确，通过最小化经验风险（即训练数据上的误差）来优化模型。
        - 公式：
          $$\min \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)})^2$$
        - 解析：
          - 这是代价函数 (Cost Function)，单纯地计算预测值 $h_\theta(x)$ 减去真实值 $y$ 的平方，然后求平均。
          - 目标：让训练集上的误差最小。
          - 潜在问题：如果只盯着这个公式优化，模型可能会为了迎合每一个样本点而变得极其扭曲，导致过拟合 (Overfitting)。

      - **结构风险最小化（SRM）**：
        - 定义：不仅关注模型的准确性，还关注模型的复杂度，通过在经验风险的基础上加入正则化项来控制模型复杂度。
        - 公式：
          $$\min \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)})^2 + \color{red}{\lambda J(h)}$$
        - 解析：
          - 这是代价函数 + 正则化项。
          - $J(h)$ (模型复杂度)：衡量模型是否过于复杂。在线性回归中，通常是参数的平方和 (L2 正则) 或绝对值和 (L1 正则)。
          - $\lambda$ (系数)：一个超参数 (Hyperparameter)。
            - 如果 $\lambda$ 很大，表示更注重模型简单性，即“宁愿误差大一点，也不要模型太复杂”。
            - 如果 $\lambda = 0$，则退化为经验风险最小化 (ERM)。
          - 本质：在“拟合好坏”和“模型繁简”之间做权衡 (Trade-off)。

- **算法**：
  - 定义：算法是用于优化模型参数以最小化损失函数的具体方法。
  - 作用：
    - 在求解最小经验风险或结构风险的过程中，通过算法找到可以让损失最小的参数。
    - 本质上是一个最优化问题。
    - 下面展示最经典的两个算法，即最小二乘法与梯度下降法。
  - 示例：
    - **最小二乘法 (Least Squares)**：
      - 类型：解析解 (Analytical Solution)。
      - 公式：
        $$\theta = (X^T X)^{-1} X^T Y$$
      - 解析：
        - 这是一个“一步到位”的数学公式。只需将数据矩阵 $X$ 和标签 $Y$ 代入，经过矩阵运算（转置、求逆、相乘），即可直接算出最优的 $\theta$。
      - 优点：
        - 不需要迭代，一次算出精确解。
      - 缺点：
        - 需要计算矩阵的逆 $(X^T X)^{-1}$，当数据量很大时（例如 $X$ 是 10万维），计算逆矩阵会非常慢，甚至可能导致内存溢出。

    - **梯度下降法 (Gradient Descent)**：
      - 类型：数值解 (Numerical Solution)。
      - 描述：
        - 这是现代 AI（尤其是深度学习）的主流算法。
        - 它不是一步算出结果，而是像下山一样，一步一步沿着梯度的反方向走，直到走到谷底。
      - 优点：
        - 适合大规模数据集。
        - 不需要计算矩阵的逆。
      - 缺点：
        - 需要迭代，收敛速度可能较慢，且对超参数（如学习率）较为敏感。

## 过拟合与欠拟合

- **过拟合（Overfitting）**：
  - 定义：模型把数据学习得太彻底，以至于把噪声数据的特征也学习到了，导致在测试时不能很好地识别数据，无法正确分类。
  - 问题：模型的泛化能力（即对新鲜样本的适应能力）太差，过分依赖训练数据。

- **欠拟合（Underfitting）**：
  - 定义：模型没有很好地捕捉到数据特征，不能很好地拟合数据。
  - 问题：未能学习训练数据中的关系，导致模型表现较差。

## 模型误差评估

对于已经训练好的模型，我们一般采用以下方法进行评估：

1. **训练误差**：
   - 定义：模型在训练集上的误差。
   - 作用：用来判断模型在训练集上的拟合能力。

2. **测试误差**：
   - 定义：模型在测试集上的误差。
   - 作用：用来判断模型在测试集上的拟合能力。
   - 说明：相比训练误差，我们更关心测试误差，因为它更能反映模型对新数据的泛化能力。

3. **泛化误差**：
   - 定义：模型在任意一个测试数据样本上表现出的误差。
   - 作用：用来评估模型对未知数据的预测能力。
   - 说明：泛化误差是衡量模型性能的关键指标，反映了模型的泛化能力。

## 机器学习方法

当我们确定机器学习的三要素（模型、策略、算法）之后，可以总结出机器学习的基本方法：

1. **获取训练数据**：得到一个有限的训练数据集合。
2. **确定假设空间**：确定包含所有可能的模型的假设空间，即学习模型的集合。
3. **确定学习策略**：确定模型选择的准则，即学习的策略。
4. **实现学习算法**：实现求解最优模型的算法，即学习的算法。
5. **选择最优模型**：通过学习的算法选择最优模型。
6. **模型应用**：利用学习的最优模型对新数据进行预测或分析。

## 模型选择

模型选择主要有两种方式：

1. **正则化**：
   - 定义：正则化是一种结构风险最小化的策略，通过控制模型复杂度来追求更好的泛化能力。
   - 作用：降低过拟合程度，提升模型的预测能力。
   - 说明：
     - 当正则化系数较大时，模型偏向简单，倾向于约束模型。
     - 当正则化系数较小时，模型会更追求每一个数据点的拟合，但可能降低泛化能力。
     - 我们通常通过调整正则化系数，找出最佳值以提升模型的泛化能力。

2. **交叉验证**：
   - 前提：
     - 如果样本数据充足，可以将数据集切分为三部分：训练集（training set）、验证集（validation set）和测试集（test set）。
     - 训练集用于训练模型，验证集用于模型选择，测试集用于最终评估学习方法。
     - 在不同复杂度的模型中，选择对验证集预测误差最小的模型。
     - 当验证集数据充足时，这种方法是有效的。
   - 问题：
     - 在许多应用中，数据是不充足的。
   - 基本思想：
     - 交叉验证通过重复使用数据来选择好的模型。
     - 将数据切分并组合为训练集与测试集，反复进行训练、测试以及模型选择。

   - 常见形式：
     - **简单交叉验证（Simple Cross-Validation）/ 留出法（Hold-out Method）**：
       - 核心逻辑：简单直接，“一刀切”。
       - 操作步骤：
         - 切分：随机将数据分为两部分，训练集（例如 70%）+ 测试集（例如 30%）。
         - 训练：用训练集训练不同参数/不同复杂度的模型。
         - 选择：用测试集计算测试误差，选出测试误差最小的模型。
       - 特点：
         - ✅ 快：只需要跑一次。
         - ❌ 不稳定：结果非常依赖数据划分方式（有一定“运气”成分）。

     - **S 折交叉验证（S-Fold / K-Fold Cross-Validation）**：
       - 重点：应用最多、最主流的交叉验证方法。
       - 核心逻辑：轮流“坐庄”，让每个样本都有机会参与测试。
       - 操作步骤：
         - 切分：将数据切分为 $S$ 个互不相交、大小（尽量）相同的子集。
         - 循环 $S$ 次：每次取 1 个子集作为测试集，其余 $S-1$ 个子集作为训练集。
         - 评估：得到 $S$ 次测试误差，取其平均值作为模型性能。
         - 选择：平均误差最小的模型胜出。
       - 特点：
         - ✅ 稳：每个样本都有机会当测试集，评估更可靠。
         - ⚖️ 成本适中：通常 $S$ 取 5 或 10。

     - **留一交叉验证（Leave-One-Out Cross-Validation, LOOCV）**：
       - 适用场景：数据非常缺乏时。
       - 核心逻辑：S 折交叉验证的极端特例。
       - 定义：当 $S = N$（样本总数）时的 S 折交叉验证。
       - 操作步骤：
         - 假设有 $N$ 个样本，循环 $N$ 次：每次只留 1 个样本作为测试集，其余 $N-1$ 个样本全部用于训练。
         - 评估：计算 $N$ 次测试误差的平均值。
         - 选择：平均误差最小的模型胜出。
       - 特点：
         - ✅ 数据利用率最高：几乎用上全部数据来训练。
         - ❌ 计算量很大：若有 1000 个样本，需要训练 1000 次模型（深度学习中通常不可行）。

